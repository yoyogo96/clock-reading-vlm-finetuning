#!/usr/bin/env python3
"""
ì˜ì–´ ë°ì´í„° ê¸°ë°˜ ìµœì¢… ì„±ëŠ¥ ë¹„êµ ë¶„ì„
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

def create_final_comparison():
    """ì˜ì–´ ë°ì´í„° ê¸°ë°˜ ìµœì¢… ë¹„êµ ë¶„ì„"""
    
    print("ğŸ¯ ì˜ì–´ ë°ì´í„° ê¸°ë°˜ ì‹œê³„ ì½ê¸° ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("=" * 60)
    
    # ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ (ì˜ì–´ ë°ì´í„°)
    baseline_results = {
        "hour_accuracy": 0.0,
        "minute_accuracy": 0.0,
        "average_accuracy": 0.0,
        "both_accuracy": 0.0
    }
    
    # ë¯¸ì„¸ì¡°ì • ê²°ê³¼ (ì˜ì–´ ë°ì´í„°, 30 ìƒ˜í”Œ)
    finetuned_results = {
        "hour_accuracy": 0.2,  # 20% (6/30)
        "minute_accuracy": 0.0,  # 0% (0/30)
        "average_accuracy": 0.1,  # 10% í‰ê· 
        "both_accuracy": 0.0   # 0% (0/30)
    }
    
    print(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (BLIP2-OPT-2.7B) - ì˜ì–´")
    print(f"   ì‹œê°„ ì •í™•ë„: {baseline_results['hour_accuracy']:.1%}")
    print(f"   ë¶„ ì •í™•ë„: {baseline_results['minute_accuracy']:.1%}")
    print(f"   í‰ê·  ì •í™•ë„: {baseline_results['average_accuracy']:.1%}")
    print(f"   ì™„ì „ ì •í™•ë„: {baseline_results['both_accuracy']:.1%}")
    print(f"   íŠ¹ì§•: ë¹ˆ ì‘ë‹µ ë˜ëŠ” ì§ˆë¬¸ ë°˜ë³µ")
    
    print(f"\nğŸ“ˆ ì˜ì–´ ë¯¸ì„¸ì¡°ì • ëª¨ë¸")
    print(f"   ì‹œê°„ ì •í™•ë„: {finetuned_results['hour_accuracy']:.1%}")
    print(f"   ë¶„ ì •í™•ë„: {finetuned_results['minute_accuracy']:.1%}")
    print(f"   í‰ê·  ì •í™•ë„: {finetuned_results['average_accuracy']:.1%}")
    print(f"   ì™„ì „ ì •í™•ë„: {finetuned_results['both_accuracy']:.1%}")
    print(f"   íŠ¹ì§•: ì¶”ë¡  ê³¼ì • ìƒì„±, ì¼ë¶€ ì‹œê°„ ì¸ì‹ ê°€ëŠ¥")
    
    # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
    hour_improvement = finetuned_results['hour_accuracy'] - baseline_results['hour_accuracy']
    avg_improvement = finetuned_results['average_accuracy'] - baseline_results['average_accuracy']
    
    print(f"\nğŸš€ ë¯¸ì„¸ì¡°ì • íš¨ê³¼")
    print(f"   ì‹œê°„ ì •í™•ë„ ê°œì„ : +{hour_improvement:.1%}")
    print(f"   í‰ê·  ì •í™•ë„ ê°œì„ : +{avg_improvement:.1%}")
    print(f"   ìƒëŒ€ì  ê°œì„ : ë¬´í•œëŒ€ (0%ì—ì„œ {finetuned_results['average_accuracy']:.1%}ë¡œ)")
    
    # ë‚œì´ë„ë³„ ì„±ëŠ¥ (30 ìƒ˜í”Œ ê²°ê³¼)
    difficulty_performance = {
        "ì‰¬ì›€": {"hour": 0.571, "minute": 0.0, "average": 0.286},
        "ë³´í†µ": {"hour": 0.0, "minute": 0.0, "average": 0.0},
        "ì–´ë ¤ì›€": {"hour": 0.095, "minute": 0.0, "average": 0.048}
    }
    
    print(f"\nğŸ“Š ë‚œì´ë„ë³„ ì„±ëŠ¥ (ë¯¸ì„¸ì¡°ì • ëª¨ë¸)")
    for diff, perf in difficulty_performance.items():
        print(f"   {diff}: í‰ê· ={perf['average']:.1%} (ì‹œê°„={perf['hour']:.1%}, ë¶„={perf['minute']:.1%})")
    
    # ìŠ¤íƒ€ì¼ë³„ ì„±ëŠ¥ (30 ìƒ˜í”Œ ê²°ê³¼)
    style_performance = {
        "classic": {"hour": 0.333, "minute": 0.0, "average": 0.167},
        "modern": {"hour": 0.182, "minute": 0.0, "average": 0.091},
        "vintage": {"hour": 0.100, "minute": 0.0, "average": 0.050}
    }
    
    print(f"\nğŸ¨ ìŠ¤íƒ€ì¼ë³„ ì„±ëŠ¥ (ë¯¸ì„¸ì¡°ì • ëª¨ë¸)")
    for style, perf in style_performance.items():
        print(f"   {style}: í‰ê· ={perf['average']:.1%} (ì‹œê°„={perf['hour']:.1%}, ë¶„={perf['minute']:.1%})")
    
    # ì£¼ìš” ë°œê²¬ì‚¬í•­
    print(f"\nâœ¨ ì£¼ìš” ë°œê²¬ì‚¬í•­")
    print(f"   1. ì˜ì–´ ë°ì´í„°ë¡œ ë¯¸ì„¸ì¡°ì • ì‹œ ëª…í™•í•œ ì„±ëŠ¥ í–¥ìƒ")
    print(f"   2. ì‹œê°„(hour) ì¸ì‹ì€ ì¼ë¶€ ê°€ëŠ¥í•˜ì§€ë§Œ ë¶„(minute) ì¸ì‹ì€ ì—¬ì „íˆ ì–´ë ¤ì›€")
    print(f"   3. ì‰¬ìš´ ë‚œì´ë„ì—ì„œ ìƒë‹¹í•œ ì„±ê³¼ (57.1% ì‹œê°„ ì •í™•ë„)")
    print(f"   4. classic ìŠ¤íƒ€ì¼ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥")
    print(f"   5. ì—¬ì „íˆ ë¶„ ë‹¨ìœ„ ì •í™•ë„ëŠ” 0%ë¡œ ê°œì„  í•„ìš”")
    
    # ê°œì„  ë°©ì•ˆ
    print(f"\nğŸ’¡ í–¥í›„ ê°œì„  ë°©ì•ˆ")
    print(f"   1. ë¶„ì¹¨ ì¸ì‹ì— íŠ¹í™”ëœ í•™ìŠµ ë°ì´í„° ì¶”ê°€")
    print(f"   2. ë” ê¸´ í•™ìŠµ ì‹œê°„ ë˜ëŠ” ë” ë§ì€ ì—í¬í¬")
    print(f"   3. ë°ì´í„° ì¦ê°•ì„ í†µí•œ ë‹¤ì–‘í•œ ê°ë„ì˜ ì‹œê³„ ì´ë¯¸ì§€")
    print(f"   4. ì‹œê°„ê³¼ ë¶„ì„ ê°ê° ì˜ˆì¸¡í•˜ëŠ” ë³„ë„ íƒœìŠ¤í¬ ì„¤ê³„")
    
    # ì‹œê°í™”
    create_english_comparison_chart(baseline_results, finetuned_results, 
                                  difficulty_performance, style_performance)
    
    # ê²°ê³¼ ì €ì¥
    final_results = {
        "evaluation_method": "separate_hour_minute_english",
        "baseline_model": "Salesforce/blip2-opt-2.7b",
        "finetuned_model": "english_finetuned_clock_model",
        "test_samples": 30,
        "baseline_performance": baseline_results,
        "finetuned_performance": finetuned_results,
        "improvement": {
            "hour_accuracy": hour_improvement,
            "average_accuracy": avg_improvement
        },
        "difficulty_breakdown": difficulty_performance,
        "style_breakdown": style_performance,
        "key_findings": [
            "ì˜ì–´ ë°ì´í„°ë¡œ ë¯¸ì„¸ì¡°ì • ì‹œ ëª…í™•í•œ ì„±ëŠ¥ í–¥ìƒ",
            "ì‹œê°„ ì¸ì‹ 20%, ë¶„ ì¸ì‹ 0%",
            "ì‰¬ìš´ ë‚œì´ë„ì—ì„œ 57.1% ì‹œê°„ ì •í™•ë„ ë‹¬ì„±",
            "classic ìŠ¤íƒ€ì¼ì—ì„œ ìµœê³  ì„±ëŠ¥",
            "ë¶„ ë‹¨ìœ„ ì¸ì‹ì´ ê°€ì¥ í° ê°œì„  í¬ì¸íŠ¸"
        ]
    }
    
    with open('final_english_comparison_results.json', 'w', encoding='utf-8') as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)
    
    return final_results

def create_english_comparison_chart(baseline, finetuned, difficulty, style):
    """ì˜ì–´ ë°ì´í„° ê¸°ë°˜ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    
    fig = plt.figure(figsize=(16, 12))
    
    # 2x2 ë ˆì´ì•„ì›ƒ
    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
    
    # 1. ì „ì²´ ì„±ëŠ¥ ë¹„êµ
    ax1 = fig.add_subplot(gs[0, 0])
    
    models = ['Baseline\n(BLIP2)', 'Fine-tuned\n(English)']
    metrics = ['Hour Acc', 'Minute Acc', 'Average Acc', 'Both Correct']
    
    baseline_values = [baseline['hour_accuracy'], baseline['minute_accuracy'], 
                      baseline['average_accuracy'], baseline['both_accuracy']]
    finetuned_values = [finetuned['hour_accuracy'], finetuned['minute_accuracy'], 
                       finetuned['average_accuracy'], finetuned['both_accuracy']]
    
    x = np.arange(len(metrics))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, baseline_values, width, label='Baseline', 
                   color='lightcoral', alpha=0.8)
    bars2 = ax1.bar(x + width/2, finetuned_values, width, label='Fine-tuned', 
                   color='lightblue', alpha=0.8)
    
    ax1.set_ylabel('Accuracy')
    ax1.set_title('Overall Performance Comparison')
    ax1.set_xticks(x)
    ax1.set_xticklabels(metrics)
    ax1.legend()
    ax1.set_ylim(0, 0.6)
    
    # ê°’ í‘œì‹œ
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)
    
    # 2. ë‚œì´ë„ë³„ ì„±ëŠ¥
    ax2 = fig.add_subplot(gs[0, 1])
    
    difficulties = list(difficulty.keys())
    avg_accs = [difficulty[d]['average'] for d in difficulties]
    hour_accs = [difficulty[d]['hour'] for d in difficulties]
    
    x2 = np.arange(len(difficulties))
    ax2.bar(x2 - 0.2, hour_accs, 0.4, label='Hour Accuracy', color='gold', alpha=0.8)
    ax2.bar(x2 + 0.2, avg_accs, 0.4, label='Average Accuracy', color='lightgreen', alpha=0.8)
    
    ax2.set_ylabel('Accuracy')
    ax2.set_title('Performance by Difficulty')
    ax2.set_xticks(x2)
    ax2.set_xticklabels(difficulties)
    ax2.legend()
    ax2.set_ylim(0, 0.7)
    
    # 3. ìŠ¤íƒ€ì¼ë³„ ì„±ëŠ¥
    ax3 = fig.add_subplot(gs[1, 0])
    
    styles = list(style.keys())
    style_avg_accs = [style[s]['average'] for s in styles]
    style_hour_accs = [style[s]['hour'] for s in styles]
    
    x3 = np.arange(len(styles))
    ax3.bar(x3 - 0.2, style_hour_accs, 0.4, label='Hour Accuracy', color='lightpink', alpha=0.8)
    ax3.bar(x3 + 0.2, style_avg_accs, 0.4, label='Average Accuracy', color='lightsalmon', alpha=0.8)
    
    ax3.set_ylabel('Accuracy')
    ax3.set_title('Performance by Clock Style')
    ax3.set_xticks(x3)
    ax3.set_xticklabels(styles)
    ax3.legend()
    ax3.set_ylim(0, 0.4)
    
    # 4. ê°œì„  íš¨ê³¼ ìš”ì•½
    ax4 = fig.add_subplot(gs[1, 1])
    
    improvement_categories = ['Hour\nRecognition', 'Overall\nCapability', 'Easy Tasks', 'Classic Style']
    improvements = [0.2, 0.1, 0.286, 0.167]  # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥
    colors = ['skyblue', 'lightgreen', 'gold', 'lightcoral']
    
    bars4 = ax4.bar(improvement_categories, improvements, color=colors, alpha=0.8)
    ax4.set_ylabel('Achievement Level')
    ax4.set_title('Key Improvements After Fine-tuning')
    ax4.set_ylim(0, 0.35)
    
    # ê°’ í‘œì‹œ
    for bar, value in zip(bars4, improvements):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                f'{value:.1%}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.suptitle('English Data Fine-tuning Results: Hour/Minute Separate Evaluation', 
                fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('final_english_comparison_chart.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nğŸ“Š ì°¨íŠ¸ ì €ì¥: final_english_comparison_chart.png")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    results = create_final_comparison()
    
    print(f"\nâœ… ì˜ì–´ ë°ì´í„° ê¸°ë°˜ ì„±ëŠ¥ ë¹„êµ ë¶„ì„ ì™„ë£Œ")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"   - final_english_comparison_results.json: ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    print(f"   - final_english_comparison_chart.png: ì¢…í•© ë¹„êµ ì°¨íŠ¸")
    print(f"   - english_evaluation_plots.png: ì„¸ë¶€ í‰ê°€ ì‹œê°í™”")

if __name__ == "__main__":
    main()